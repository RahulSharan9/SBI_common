import os
import pandas as pd

# >>> EDIT THIS <<<
# Only these columns will be consolidated
list_of_columns = ["A", "X", "Y"]

# Base folder where quarter subfolders exist
base_dir = "output_folder"

all_rows = []

# Walk through all quarter folders
for quarter in os.listdir(base_dir):
    quarter_path = os.path.join(base_dir, quarter)
    if not os.path.isdir(quarter_path):
        continue

    data_quality_path = os.path.join(quarter_path, "data_quality")
    if not os.path.isdir(data_quality_path):
        continue

    # Look for possible value_counts CSVs
    for fname in os.listdir(data_quality_path):
        if fname.endswith(".csv") and "value" in fname.lower():
            fpath = os.path.join(data_quality_path, fname)

            df = pd.read_csv(fpath)

            # Normalize column names
            df.columns = df.columns.str.strip().str.lower()

            required_cols = {"value", "count", "file", "column"}
            if not required_cols.issubset(df.columns):
                continue

            # <<< FILTER APPLIED HERE >>>
            df = df[df["column"].isin(list_of_columns)]
            if df.empty:
                continue

            # Extract segment from filename, case-insensitive, handle underscores
            df["segment"] = df["file"].str.extract(r"(seg_?\d+)", flags=pd.RegexFlags.IGNORECASE, expand=False)
            df["segment"] = df["segment"].str.replace("_","").str.upper()  # normalize SEG_1 -> SEG1

            # Add quarter metadata
            df["quarter"] = quarter

            all_rows.append(df)

# Combine outputs
if all_rows:
    final_df = pd.concat(all_rows, ignore_index=True)
    # Reorder columns for clarity
    final_df = final_df[["quarter", "segment", "column", "value", "count", "file"]]

    final_df.to_csv("consolidated_value_counts.csv", index=False)
    print("✅ Summary generated: consolidated_value_counts.csv")
    display(final_df.head(20))

else:
    print("⚠️ No matching rows found for your selected columns.")
