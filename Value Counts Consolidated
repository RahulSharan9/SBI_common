import pandas as pd
import os

root = r"path/to/output_folder"
list_of_columns = ["COLA", "COLB", "COLC"]  # <-- your filter cols

all_dfs = []

for quarter in os.listdir(root):
    quarter_path = os.path.join(root, quarter)
    vc_path = os.path.join(quarter_path, "data_quality")

    if not os.path.exists(vc_path):
        continue

    for f in os.listdir(vc_path):
        if "value_counts" in f.lower() and f.endswith(".csv"):
            fpath = os.path.join(vc_path, f)
            df = pd.read_csv(fpath)

            # attach quarter
            df["quarter"] = quarter

            # filter columns
            df = df[df["column"].isin(list_of_columns)]

            # extract segment from filename (strip .parquet)
            df["segment"] = df["file"].str.replace(".parquet", "", regex=False)

            all_dfs.append(df)

# Combine everything
combined_df = pd.concat(all_dfs, ignore_index=True)

# Summarize across quarters
summary_df = combined_df.groupby(["segment", "column", "value"], as_index=False)["count"].sum()

# Sort better
summary_df = summary_df.sort_values(["segment", "column", "count"], ascending=[True, True, False])

summary_df.to_csv("value_counts_consolidated.csv", index=False)

print("âœ… Done. Output: value_counts_consolidated.csv")
