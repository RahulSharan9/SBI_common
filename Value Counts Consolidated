import os
import pandas as pd
import re

# >>> EDIT THIS <<<
list_of_columns = ["X", "A", "Y"]  # columns you want to consolidate (uppercase)
base_dir = "output_folder"

all_rows = []

for quarter in os.listdir(base_dir):
    quarter_path = os.path.join(base_dir, quarter)
    if not os.path.isdir(quarter_path):
        continue

    data_quality_path = os.path.join(quarter_path, "data_quality")
    if not os.path.isdir(data_quality_path):
        continue

    for fname in os.listdir(data_quality_path):
        if fname.endswith(".csv") and "value" in fname.lower():
            fpath = os.path.join(data_quality_path, fname)
            df = pd.read_csv(fpath)

            # Normalize column names
            df.columns = df.columns.str.strip().str.lower()

            required_cols = {"value", "count", "file", "column"}
            if not required_cols.issubset(df.columns):
                continue

            # Uppercase column names to match your provided list
            df["column"] = df["column"].str.upper()

            # ✅ Filter only required columns (NOW works)
            df = df[df["column"].isin(list_of_columns)]
            if df.empty:
                continue

            # ✅ More flexible SEGMENT extraction
            df["segment"] = df["file"].str.extract(r"(seg[_]?\d+)", expand=False)
            df["segment"] = df["segment"].str.upper().str.replace("_","")

            all_rows.append(df)

# Aggregate
if all_rows:
    combined_df = pd.concat(all_rows, ignore_index=True)

    summary_df = (combined_df
                  .groupby(["segment", "column", "value"], as_index=False)["count"]
                  .sum()
                  .rename(columns={"count": "total_count"}))

    summary_df.to_csv("consolidated_value_counts_across_quarters.csv", index=False)

    print("✅ DONE — saved consolidated_value_counts_across_quarters.csv")
    print(summary_df.head(20))

else:
    print("⚠️ No matching rows found. Check column names or folder structure.")
